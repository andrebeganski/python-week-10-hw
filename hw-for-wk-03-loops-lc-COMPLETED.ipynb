{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz4lidEcC-wu"
   },
   "source": [
    "# Homework for Week 3\n",
    "\n",
    "The goal for this homework is to see the relevant journalistic uses for what we learned in class in week 4.\n",
    "\n",
    "1. Using the power of automation for iterate through tedious, but important tasks.\n",
    "2. Tapping Python to iterate through calculations. In a few weeks, you'll be doing this on millions of rows.\n",
    "3. Allowing us to slow down how fast our code runs to avoid detection or being blocked when we start scraping websites!\n",
    "4. Processing data we have scraped into dataframes and/or csv files for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Counter\n",
    "* Build a counter that counts from 2 to 10, but only even numbers.\n",
    "* Print the counter numbers in statement that reads: \"The even number is [whatever the even number is]\".\n",
    "* Once it reaches 10, it should print \"Done counting from 2 to 10 even numbers!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The even number is 2\n",
      "The even number is 4\n",
      "The even number is 6\n",
      "The even number is 8\n",
      "Done counting from 2 to 10 even numbers\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "\n",
    "counter = 2\n",
    "\n",
    "while counter < 10:\n",
    "    print(f\"The even number is {counter}\")\n",
    "    counter = counter + 2\n",
    "else:\n",
    "    print(\"Done counting from 2 to 10 even numbers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a counter with a timer\n",
    "* Add a timer to the previous code so it runs every 3 to 15 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The even number is 2\n",
      "Let's sleep for 11\n",
      "The even number is 4\n",
      "Let's sleep for 13\n",
      "The even number is 6\n",
      "Let's sleep for 11\n",
      "The even number is 8\n",
      "Let's sleep for 5\n",
      "Done counting from 2 to 10 even numbers!\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "counter = 2\n",
    "\n",
    "while counter < 10:\n",
    "    sleepy = randint(3,15)\n",
    "    print(f\"The even number is {counter}\")\n",
    "    counter = counter + 2\n",
    "    print(f\"Let's sleep for {sleepy}\")\n",
    "    time.sleep(sleepy)\n",
    "else:\n",
    "    print(\"Done counting from 2 to 10 even numbers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEXSVGi2C-w4"
   },
   "source": [
    "## 3.  Combine different data points together \n",
    "\n",
    "#### You scrape some URLs and place them in a list called myURLS (provided below):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mQwOrDIWC-w4"
   },
   "outputs": [],
   "source": [
    "## run this cell to activate the list\n",
    "myURLS = [\n",
    "    'great-unique-data-1.html',\n",
    "    'great-unique-data-2.html',\n",
    "    'great-unique-data-3.html',\n",
    "    'great-unique-data-4.html',\n",
    "    'great-unique-data-5.html',\n",
    "    'great-unique-data-6.html',\n",
    "    'great-unique-data-7.html',\n",
    "    'great-unique-data-8.html',\n",
    "    'great-unique-data-9.html',\n",
    "    'great-unique-data-10.html',\n",
    "    'great-unique-data-11.html',\n",
    "    'great-unique-data-12.html',\n",
    "    'great-unique-data-13.html',\n",
    "    'great-unique-data-14.html',\n",
    "    'great-unique-data-15.html'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGrsmmioC-w4",
    "outputId": "daf42c56-696e-45c5-daec-967ea4801db2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great-unique-data-1.html',\n",
       " 'great-unique-data-2.html',\n",
       " 'great-unique-data-3.html',\n",
       " 'great-unique-data-4.html',\n",
       " 'great-unique-data-5.html',\n",
       " 'great-unique-data-6.html',\n",
       " 'great-unique-data-7.html',\n",
       " 'great-unique-data-8.html',\n",
       " 'great-unique-data-9.html',\n",
       " 'great-unique-data-10.html',\n",
       " 'great-unique-data-11.html',\n",
       " 'great-unique-data-12.html',\n",
       " 'great-unique-data-13.html',\n",
       " 'great-unique-data-14.html',\n",
       " 'great-unique-data-15.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CALL myURLS to check it out\n",
    "myURLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W4WZ9-_C-w5"
   },
   "source": [
    "### * You realize that these URLs are missing the base of \"http://www.importantsite.com/\"\n",
    "### * Use a ```for loop``` to join the base URL to every partial URL in your list.\n",
    "### * Print each FULL URL\n",
    "It should look like: ```\"http://www.importantsite.com/great-unique-data-14.html``` but with unique numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFqX3JypC-w5",
    "outputId": "7322e6a3-c720-455b-e9fe-965e185f51bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.importantsite.com/great-unique-data-1.html\n",
      "http://www.importantsite.com/great-unique-data-2.html\n",
      "http://www.importantsite.com/great-unique-data-3.html\n",
      "http://www.importantsite.com/great-unique-data-4.html\n",
      "http://www.importantsite.com/great-unique-data-5.html\n",
      "http://www.importantsite.com/great-unique-data-6.html\n",
      "http://www.importantsite.com/great-unique-data-7.html\n",
      "http://www.importantsite.com/great-unique-data-8.html\n",
      "http://www.importantsite.com/great-unique-data-9.html\n",
      "http://www.importantsite.com/great-unique-data-10.html\n",
      "http://www.importantsite.com/great-unique-data-11.html\n",
      "http://www.importantsite.com/great-unique-data-12.html\n",
      "http://www.importantsite.com/great-unique-data-13.html\n",
      "http://www.importantsite.com/great-unique-data-14.html\n",
      "http://www.importantsite.com/great-unique-data-15.html\n"
     ]
    }
   ],
   "source": [
    "## build here:\n",
    "\n",
    "for URL in myURLS:\n",
    "    URL = \"http://www.importantsite.com/\" + URL\n",
    "    print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-DNZj4OC-w5",
    "outputId": "d6a7b497-56fb-47bd-aed1-4f9cd19ae2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no!\n"
     ]
    }
   ],
   "source": [
    "## call myURLS.\n",
    "## do they have the full url?\n",
    "myURLS\n",
    "print(\"no!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM6-d1hXC-w5"
   },
   "source": [
    "## 4. Update myURLS and store full URLS in a new list\n",
    "\n",
    "#### * Instead of just printing the joined URLs, create a new list called ```full_URLS`` that holds the full URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vggh0aYAC-w5",
    "outputId": "7e1f46d1-0b1c-4784-c838-798bea161370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.importantsite.com/great-unique-data-1.html',\n",
       " 'http://www.importantsite.com/great-unique-data-2.html',\n",
       " 'http://www.importantsite.com/great-unique-data-3.html',\n",
       " 'http://www.importantsite.com/great-unique-data-4.html',\n",
       " 'http://www.importantsite.com/great-unique-data-5.html',\n",
       " 'http://www.importantsite.com/great-unique-data-6.html',\n",
       " 'http://www.importantsite.com/great-unique-data-7.html',\n",
       " 'http://www.importantsite.com/great-unique-data-8.html',\n",
       " 'http://www.importantsite.com/great-unique-data-9.html',\n",
       " 'http://www.importantsite.com/great-unique-data-10.html',\n",
       " 'http://www.importantsite.com/great-unique-data-11.html',\n",
       " 'http://www.importantsite.com/great-unique-data-12.html',\n",
       " 'http://www.importantsite.com/great-unique-data-13.html',\n",
       " 'http://www.importantsite.com/great-unique-data-14.html',\n",
       " 'http://www.importantsite.com/great-unique-data-15.html']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build here:\n",
    "full_urls = []\n",
    "for URL in myURLS:\n",
    "    URL = \"http://www.importantsite.com/\" + URL\n",
    "    full_urls.append(URL)\n",
    "full_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. You have a long list of toxins. Run the next cell to pull the list into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxins = [\n",
    "        \"Recombinant Bovine Growth Hormone\", \n",
    "        \"Butylated Hydroxyanisole\", \n",
    "        \"Sodium Aluminum Sulphate\",\n",
    "        \"Potassium Aluminum Sulphate\",\n",
    "        \"Sodium Nitrite\",\n",
    "        \"Polycyclic Aromatic Hydrocarbons\",\n",
    "        \"Dioxins\",\n",
    "        \"Heterocyclic Amines\",\n",
    "        \"Butylated Hydroxytoluene\",\n",
    "        \"Polyvinyl Chloride\",\n",
    "        \"PVC\",\n",
    "        \"Perfluorooctanoic Acid\",\n",
    "        \"PFOA\",\n",
    "        \"Triclosan\",\n",
    "        \"Bisphenol-A\",\n",
    "        \"BPA\",\n",
    "        \"Formaldehyde\",\n",
    "        \"Naphthalene\",\n",
    "        \"Asbestos\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You realize that the toxins from \"Polyvinyl Chloride\" to the end of the list are hormone disruptors.\n",
    "\n",
    "Programmatically create a new list using List Comprehension called ```hormone_inhibitors``` that includes all the chemicals from \"Polyvinyl Chloride\" to \"Asbestos\".\n",
    "\n",
    "- Do NOT manually count to figure out the index position of \"Polyvinyl Chloride\".\n",
    "- Do NOT manually type out a new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "## we can figure out the position for \"Polyvinyl Chloride\"\n",
    "toxins.index(\"Polyvinyl Chloride\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Polyvinyl Chloride',\n",
       " 'PVC',\n",
       " 'Perfluorooctanoic Acid',\n",
       " 'PFOA',\n",
       " 'Triclosan',\n",
       " 'Bisphenol-A',\n",
       " 'BPA',\n",
       " 'Formaldehyde',\n",
       " 'Naphthalene',\n",
       " 'Asbestos']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## in one line we can call the index position all the way to the end.\n",
    "hormone_inhibitors = toxins[9:]\n",
    "hormone_inhibitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using a ```for loop``` create a list called ```sodium_fl``` that captures only the toxins that have the word ```sodium``` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sodium Aluminum Sulphate', 'Sodium Nitrite']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build it here\n",
    "sodium_fl = []\n",
    "for toxin in toxins:\n",
    "    if \"Sodium\" in toxin:\n",
    "        sodium_fl.append(toxin) \n",
    "sodium_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using a ```list comprehension``` create a list called ```sodium_lc``` that captures only the toxins that have the word ```sodium``` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_IubbqlC-w4",
    "outputId": "b680eae8-4ed3-4e0f-bf4b-f96ca0a17f46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sodium Aluminum Sulphate', 'Sodium Nitrite']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build here: \n",
    "sodium_cl = [toxin for toxin in toxins if \"Sodium\" in toxin]\n",
    "sodium_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ```for loop``` Calculations\n",
    "\n",
    "Run the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this cell\n",
    "monthly_rent_2022 = [3500, 2700, 1200, 5000, 3500, 2000, 4300, 3400, 3900 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this fast gentrifying neighborhood, the monthly rent will increase by 27.8 percent for 2023.  Using a ```for loop``` create a new list called ```monthly_rent_2023_fl``` that shows the increased rent rounded to ZERO decimal places. \n",
    "\n",
    "Do the calculation programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4473, 3451, 1534, 6390, 4473, 2556, 5495, 4345, 4984]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "monthly_rent_2023_fl = []\n",
    "for rent in monthly_rent_2022:\n",
    "    rent = rent * 1.278\n",
    "    monthly_rent_2023_fl.append(int(round(rent,0)))\n",
    "monthly_rent_2023_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ```list comprehension``` Calculation\n",
    "\n",
    "The same scenario as above but now create a list called ```monthly_rent_2023_lc``` using ```list comprehension```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4473, 3451, 1534, 6390, 4473, 2556, 5495, 4345, 4984]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### answer here (create more cells if necessary)\n",
    "monthly_rent_2023_lc = [int(round(rent * 1.278,0)) for rent in monthly_rent_2022]\n",
    "monthly_rent_2023_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ```zip``` it\n",
    "\n",
    "You scrape a website and end up with the lists below.\n",
    "\n",
    "Use both the methods we covered in class to create a ```df``` and then a ```csv``` file from these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The content you scraped is now in the following lists:\n",
    "\n",
    "source_files = ['7681804Q.pdf', '7543447R.pdf', '7864672J.pdf', '8073426Q.pdf', '7909756P.pdf', '7749758M.pdf', '7917101M.pdf', '7880385Y.pdf', '7958281Z.pdf', '7836909K.pdf', '7891371L.pdf', '7096205N.pdf']\n",
    "\n",
    "date_appeals = ['10-Jan-18', '31-May-17', '20-Nov-18', '6-Dec-19', '12-Feb-19', '1-May-18', '25-Feb-19', '18-Dec-18', '8-May-19', '2-Oct-18', '8-Jan-19', '6-Aug-15']\n",
    "\n",
    "cognition_related = [False, True, False, False, True, False, False, True, True, True, False, False]\n",
    "\n",
    "positive_decisions = [False, True, True, False, False, True, True, True, True, True, False, True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A- Use the zip() into list of dictionaries method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_file': '7681804Q.pdf',\n",
       "  'date_appealed': '10-Jan-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False},\n",
       " {'source_file': '7543447R.pdf',\n",
       "  'date_appealed': '31-May-17',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_file': '7864672J.pdf',\n",
       "  'date_appealed': '20-Nov-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True},\n",
       " {'source_file': '8073426Q.pdf',\n",
       "  'date_appealed': '6-Dec-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False},\n",
       " {'source_file': '7909756P.pdf',\n",
       "  'date_appealed': '12-Feb-19',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': False},\n",
       " {'source_file': '7749758M.pdf',\n",
       "  'date_appealed': '1-May-18',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True},\n",
       " {'source_file': '7917101M.pdf',\n",
       "  'date_appealed': '25-Feb-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True},\n",
       " {'source_file': '7880385Y.pdf',\n",
       "  'date_appealed': '18-Dec-18',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_file': '7958281Z.pdf',\n",
       "  'date_appealed': '8-May-19',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_file': '7836909K.pdf',\n",
       "  'date_appealed': '2-Oct-18',\n",
       "  'cognition_related': True,\n",
       "  'positive_decision': True},\n",
       " {'source_file': '7891371L.pdf',\n",
       "  'date_appealed': '8-Jan-19',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': False},\n",
       " {'source_file': '7096205N.pdf',\n",
       "  'date_appealed': '6-Aug-15',\n",
       "  'cognition_related': False,\n",
       "  'positive_decision': True}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here – create more cells as necessary\n",
    "dict_method = []\n",
    "for (s_file, date_apls, cogn_rltd, pos_decs)\\\n",
    "in zip(source_files, date_appeals, cognition_related, positive_decisions):\n",
    "    dict_method.append({\n",
    "        \"source_file\": s_file,\n",
    "        \"date_appealed\": date_apls,\n",
    "        \"cognition_related\": cogn_rltd,\n",
    "        \"positive_decision\": pos_decs,\n",
    "    })\n",
    "dict_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- Use the zip() into list of tuples method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7681804Q.pdf', '10-Jan-18', False, False),\n",
       " ('7543447R.pdf', '31-May-17', True, True),\n",
       " ('7864672J.pdf', '20-Nov-18', False, True),\n",
       " ('8073426Q.pdf', '6-Dec-19', False, False),\n",
       " ('7909756P.pdf', '12-Feb-19', True, False),\n",
       " ('7749758M.pdf', '1-May-18', False, True),\n",
       " ('7917101M.pdf', '25-Feb-19', False, True),\n",
       " ('7880385Y.pdf', '18-Dec-18', True, True),\n",
       " ('7958281Z.pdf', '8-May-19', True, True),\n",
       " ('7836909K.pdf', '2-Oct-18', True, True),\n",
       " ('7891371L.pdf', '8-Jan-19', False, False),\n",
       " ('7096205N.pdf', '6-Aug-15', False, True)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here – create more cells as necessary\n",
    "tuples_method = []\n",
    "\n",
    "for item in zip(source_files, date_appeals, cognition_related, positive_decisions):\n",
    "    tuples_method.append(item)\n",
    "tuples_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just harnessed the power of Python to accomplish the following tasks that are critical foundational skills to become an advanced data journalist:\n",
    "\n",
    "1. Using the power of automation for iterate through tedious, but important tasks.\n",
    "2. Tapping Python to iterate through calculations. In a few weeks, you'll be doing this on millions of rows.\n",
    "3. Allowing us to slow down how fast our code runs to avoid detection or being blocked when we start scraping websites!\n",
    "4. Processing data we have scraped into dataframes and/or csv files for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-for-week-3-SOLUTIONS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
